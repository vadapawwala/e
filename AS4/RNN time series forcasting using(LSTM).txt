import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.model_selection import train_test_split

# Load the dataset
data = pd.read_csv('/content/monthly-milk-production-pounds.csv')

# Preprocess the dataset
data['Month'] = pd.to_datetime(data['Month'])  # Convert 'Month' column to datetime
data.set_index('Month', inplace=True)          # Set 'Month' as index

# Plot the dataset
plt.figure(figsize=(10, 6))
plt.plot(data, label="Monthly Milk Production")
plt.title('Monthly Milk Production')
plt.xlabel('Date')
plt.ylabel('Milk Production')
plt.legend()
plt.show()

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Convert time series to supervised learning problem
def create_dataset(series, time_step=1):
    X, y = [], []
    for i in range(len(series) - time_step - 1):
        X.append(series[i:(i + time_step), 0])
        y.append(series[i + time_step, 0])
    return np.array(X), np.array(y)

# Parameters
time_step = 12  # Use 12 months (1 year) to predict the next month

# Create training and test datasets
X, y = create_dataset(scaled_data, time_step)
X = X.reshape(X.shape[0], X.shape[1], 1)  # Reshape for LSTM input

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# Build the LSTM model
model = Sequential()
model.add(LSTM(units=100, return_sequences=True, input_shape=(time_step, 1)))
model.add(LSTM(units=100, return_sequences=False))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), verbose=1)

# Make predictions
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

# Inverse transform to get actual values
train_predict = scaler.inverse_transform(train_predict)
test_predict = scaler.inverse_transform(test_predict)
y_train_actual = scaler.inverse_transform([y_train])
y_test_actual = scaler.inverse_transform([y_test])

# Plot the results
plt.figure(figsize=(10, 6))
plt.plot(data.index, data.values, label='Actual Data')
plt.plot(data.index[time_step:len(train_predict) + time_step], train_predict, label='Train Predictions')
plt.plot(data.index[len(train_predict) + time_step + 1:], test_predict, label='Test Predictions')
plt.title('Milk Production Forecasting')
plt.xlabel('Date')
plt.ylabel('Milk Production')
plt.legend()
plt.show()

# Evaluate the model
train_loss = model.evaluate(X_train, y_train, verbose=2)
test_loss = model.evaluate(X_test, y_test, verbose=2)

print(f"Train Loss: {train_loss}")
print(f"Test Loss: {test_loss}")