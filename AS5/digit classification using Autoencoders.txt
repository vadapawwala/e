import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models, datasets
from tensorflow.keras.utils import to_categorical

# Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()

# Preprocess the data
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))
x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))

# Build the autoencoder model
input_img = layers.Input(shape=(28, 28, 1))

# Encoder
x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
x = layers.MaxPooling2D((2, 2), padding='same')(x)
x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)
encoded = layers.MaxPooling2D((2, 2), padding='same')(x)

# Decoder
x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)
x = layers.UpSampling2D((2, 2))(x)
x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)
x = layers.UpSampling2D((2, 2))(x)
decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)

# Autoencoder model
autoencoder = models.Model(input_img, decoded)

# Compile the model
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Train the autoencoder
autoencoder.fit(x_train, x_train, epochs=10, batch_size=256, shuffle=True, validation_data=(x_test, x_test))

# Encode the images
encoder = models.Model(input_img, encoded)
encoded_train = encoder.predict(x_train)
encoded_test = encoder.predict(x_test)

# Prepare for classification
encoded_train_flat = encoded_train.reshape(-1, 7 * 7 * 16)  # Flatten the encoded representation
encoded_test_flat = encoded_test.reshape(-1, 7 * 7 * 16)

# Convert labels to categorical
y_train_cat = to_categorical(y_train, num_classes=10)
y_test_cat = to_categorical(y_test, num_classes=10)

# Build the classifier model
classifier = models.Sequential()
classifier.add(layers.Dense(128, activation='relu', input_shape=(7 * 7 * 16,)))
classifier.add(layers.Dense(10, activation='softmax'))

# Compile the classifier
classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the classifier
classifier.fit(encoded_train_flat, y_train_cat, epochs=50, batch_size=256, validation_data=(encoded_test_flat, y_test_cat))

# Evaluate the classifier
test_loss, test_acc = classifier.evaluate(encoded_test_flat, y_test_cat)

# Make predictions on the test set
y_pred = classifier.predict(encoded_test_flat)
y_pred_classes = np.argmax(y_pred, axis=1)  # Get predicted class labels
y_true_classes = np.argmax(y_test_cat, axis=1)  # Get true class labels

# Calculate the number of correct predictions
correct_predictions = np.sum(y_pred_classes == y_true_classes)
total_predictions = len(y_true_classes)

# Display results
print(f'Test accuracy: {test_acc}')
print(f'Total number of predictions: {total_predictions}')
print(f'Number of correct predictions: {correct_predictions}')

